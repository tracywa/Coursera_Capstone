{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.7.12\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  added / updated specs: \n",
      "    - geopy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    scikit-learn-0.20.1        |   py36h22eb022_0         5.7 MB\n",
      "    liblapack-3.8.0            |      11_openblas          10 KB  conda-forge\n",
      "    scipy-1.3.2                |   py36h921218d_0        18.0 MB  conda-forge\n",
      "    geographiclib-1.50         |             py_0          34 KB  conda-forge\n",
      "    libopenblas-0.3.6          |       h5a2b251_2         7.7 MB\n",
      "    liblapacke-3.8.0           |      11_openblas          10 KB  conda-forge\n",
      "    numpy-1.17.3               |   py36h95a1406_0         5.2 MB  conda-forge\n",
      "    libcblas-3.8.0             |      11_openblas          10 KB  conda-forge\n",
      "    libblas-3.8.0              |      11_openblas          10 KB  conda-forge\n",
      "    geopy-1.20.0               |             py_0          57 KB  conda-forge\n",
      "    blas-2.11                  |         openblas          10 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        36.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    geographiclib: 1.50-py_0                              conda-forge\n",
      "    geopy:         1.20.0-py_0                            conda-forge\n",
      "    libblas:       3.8.0-11_openblas                      conda-forge\n",
      "    libcblas:      3.8.0-11_openblas                      conda-forge\n",
      "    liblapack:     3.8.0-11_openblas                      conda-forge\n",
      "    liblapacke:    3.8.0-11_openblas                      conda-forge\n",
      "    libopenblas:   0.3.6-h5a2b251_2                                  \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    blas:          1.1-openblas                           conda-forge --> 2.11-openblas         conda-forge\n",
      "    numpy:         1.16.2-py36_blas_openblash1522bff_0    conda-forge [blas_openblas] --> 1.17.3-py36h95a1406_0 conda-forge\n",
      "    scipy:         1.2.1-py36_blas_openblash1522bff_0     conda-forge [blas_openblas] --> 1.3.2-py36h921218d_0  conda-forge\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "    scikit-learn:  0.20.1-py36_blas_openblashebff5e3_1200 conda-forge [blas_openblas] --> 0.20.1-py36h22eb022_0            \n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "scikit-learn-0.20.1  | 5.7 MB    | ##################################### | 100% \n",
      "liblapack-3.8.0      | 10 KB     | ##################################### | 100% \n",
      "scipy-1.3.2          | 18.0 MB   | ##################################### | 100% \n",
      "geographiclib-1.50   | 34 KB     | ##################################### | 100% \n",
      "libopenblas-0.3.6    | 7.7 MB    | ##################################### | 100% \n",
      "liblapacke-3.8.0     | 10 KB     | ##################################### | 100% \n",
      "numpy-1.17.3         | 5.2 MB    | ##################################### | 100% \n",
      "libcblas-3.8.0       | 10 KB     | ##################################### | 100% \n",
      "libblas-3.8.0        | 10 KB     | ##################################### | 100% \n",
      "geopy-1.20.0         | 57 KB     | ##################################### | 100% \n",
      "blas-2.11            | 10 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Solving environment: \\ "
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "\n",
    "# standard libraries\n",
    "import numpy as np                        # library to handle data in a vectorized manner\n",
    "import pandas as pd                       # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Foursquare\n",
    "!conda install -c conda-forge geopy --yes  # find latitude/longitude of a place by name\n",
    "from geopy.geocoders import Nominatim      # convert an address into latitude and longitude values\n",
    "\n",
    "# JSON files\n",
    "import json # library to handle JSON files\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize  # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# plotting data\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# map display\n",
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "import folium                             # map rendering library\n",
    "\n",
    "# other functions\n",
    "!pip install lxml                         # for read_html\n",
    "!pip install beautifulsoup4               # requested by read_html\n",
    "import itertools\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of major cities in California\n",
    "# source: Wikipedia \"List of largest California Cities\"\n",
    "\n",
    "lCities = pd.read_html('https://en.wikipedia.org/wiki/List_of_largest_California_cities_by_population')\n",
    "dfCities = pd.DataFrame(lCities[0])    # add [0] to capture table properly\n",
    "dfCities.head(10)                      # view first rows to verify dataframe looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foursquare credentials\n",
    "\n",
    "CLIENT_ID = 'XO2ABQ5J2EXXKQJTQNMEHEQVMSPBRE1AWOWMD0AOVDL2YG1S'     # your Foursquare ID\n",
    "CLIENT_SECRET = '22IN2LGH2IWXTMTKDEU4PQRAIEVOEM2V5HMVFC2WI5IWNLRZ' # your Foursquare Secret\n",
    "VERSION = '20180605'                                               # Foursquare API version\n",
    "\n",
    "print('Foursquare credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extracts the category of the venue\n",
    "# from class example\n",
    "\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from foursquare\n",
    "\n",
    "nMax = 100                            # set maximum number of responses\n",
    "# note: for a venues/explore?near query, if a radius is not specified,\n",
    "# the default is \"city-wide,\" so do not specify a radius for this query\n",
    "\n",
    "# use first (largest) city in California, Los Angeles\n",
    "xCity = dfCities.loc[0, 'City'] + ', CA'\n",
    "print(xCity)\n",
    "\n",
    "# the foursquare categoryId for \"EV Charging Station\" is 5032872391d4c4b30a586d64 (from foursquare documentation)\n",
    "xCharging = '5032872391d4c4b30a586d64'\n",
    "\n",
    "# construct URL\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&v={}&near={}&categoryId={}&limit={}'.format(\n",
    "CLIENT_ID, CLIENT_SECRET, VERSION, xCity, xCharging, nMax)\n",
    "    \n",
    "results = requests.get(url).json()\n",
    "venues = results['response']['groups'][0]['items']\n",
    "lStations = json_normalize(venues) # flatten JSON\n",
    "filtered_columns = ['venue.id', 'venue.name', 'venue.location.lat', 'venue.location.lng', 'venue.location.city']\n",
    "lStations = lStations.loc[:, filtered_columns]\n",
    "print(lStations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom lists of venues in each of several amenity classes:\n",
    "# restaurants, entertainment, lodging, leisurely shopping, services, \n",
    "# links to other forms of transportation\n",
    "# note: I chose to populate dataframe manually in this notebook in order\n",
    "# to remove need for a supporting external file\n",
    "\n",
    "# create tuples of venue categories in category classes, such as\n",
    "# \"long duration shopping\" or \"entertainment\"\n",
    "# created manually from foursquare.com list of possible categories\n",
    "# note: I selected these categories as potentially compatible activities\n",
    "# for concurrent EV charging, based on the idea that these activities would\n",
    "# typically take over 30 minutes and generally an hour or two, allowing\n",
    "# sufficient time for at least a partial EV charge\n",
    "# ideas for improvement: justify categories in each list using average \"wait times\" \n",
    "# from source such as Google Maps or a wait time study, or provide an interface for\n",
    "# the user to select categories of interest from a list\n",
    "\n",
    "lRestaurants = [('Food', '4d4b7105d754a06374d81259'),\n",
    "               ('Street Food Gathering', '53e0feef498e5aac066fd8a9')]\n",
    "tRestaurants = ['Restaurants'] * len(lRestaurants)\n",
    "lEntertainment = [('Arts & Entertainment', '4d4b7104d754a06370d81259'),\n",
    "                  ('Boat Rental', '5744ccdfe4b0c0459246b4c1'),\n",
    "                  ('College Stadium', '4bf58dd8d48988d1b4941735'),\n",
    "                  ('College Theater', '4bf58dd8d48988d1ac941735'),\n",
    "                  ('Event', '4d4b7105d754a06373d81259'),\n",
    "                  ('Night Market', '53e510b7498ebcb1801b55d4'),\n",
    "                  ('Outdoors & Recreation', '4d4b7105d754a06377d81259'),\n",
    "                  ('Community Center', '52e81612bcbc57f1066b7a34'),\n",
    "                  ('Cultural Center', '52e81612bcbc57f1066b7a32')]\n",
    "tEntertainment = ['Entertainment'] * len(lEntertainment)\n",
    "lLodging = [('Hotel', '4bf58dd8d48988d1fa931735')]\n",
    "tLodging = ['Lodging'] * len(lLodging)\n",
    "lShopping = [('Big Box Store', '52f2ab2ebcbc57f1066b8b42'),\n",
    "             ('Farmers Market', '4bf58dd8d48988d1fa941735'),\n",
    "             ('Grocery Store', '4bf58dd8d48988d118951735'),\n",
    "             ('Market', '50be8ee891d4fa8dcc7199a7'),\n",
    "             ('Organic Grocery', '52f2ab2ebcbc57f1066b8b45'),\n",
    "             ('Outlet Mall', '5744ccdfe4b0c0459246b4df'),\n",
    "             ('Shopping Mall', '4bf58dd8d48988d1fd941735'),\n",
    "             ('Shopping Plaza', '5744ccdfe4b0c0459246b4dc'),\n",
    "             ('Supermarket', '52f2ab2ebcbc57f1066b8b46'),\n",
    "             ('Warehouse Store', '52e816a6bcbc57f1066b7a54')]\n",
    "tShopping = ['Long Stop Shopping'] * len(lShopping)\n",
    "lServices = [('Library', '4bf58dd8d48988d12f941735'),\n",
    "             ('Medical Center', '4bf58dd8d48988d104941735'),\n",
    "             ('Internet Cafe', '4bf58dd8d48988d1f0941735')]\n",
    "tServices = ['Long Stop Services'] * len(lServices)\n",
    "lTransportation = [('Boat or Ferry', '4bf58dd8d48988d12d951735'),\n",
    "                   ('Bus Station', '4bf58dd8d48988d1fe931735'),\n",
    "                   ('Light Rail Station', '4bf58dd8d48988d1fc931735'),\n",
    "                   ('Metro Station', '4bf58dd8d48988d1fd931735'),\n",
    "                   ('Train Station', '4bf58dd8d48988d129951735'),\n",
    "                   ('Tram Station', '52f2ab2ebcbc57f1066b8b51')]\n",
    "tTransportation = ['Transportation Park-Ride Links'] * len(lTransportation)\n",
    "\n",
    "# merge class lists into dfClasses dataframe\n",
    "dfClassR = pd.DataFrame(tRestaurants, columns=['class'])\n",
    "dfClassE = pd.DataFrame(tEntertainment, columns=['class'])\n",
    "dfClassL = pd.DataFrame(tLodging, columns=['class'])\n",
    "dfClassS = pd.DataFrame(tShopping, columns=['class'])\n",
    "dfClassV = pd.DataFrame(tServices, columns=['class'])\n",
    "dfClassT = pd.DataFrame(tTransportation, columns=['class'])\n",
    "dfClasses = pd.concat([dfClassR, dfClassE, dfClassL, dfClassS,\n",
    "                      dfClassV, dfClassT], ignore_index=True)\n",
    "\n",
    "dfCatR = pd.DataFrame(lRestaurants, columns=['cat_name', 'cat_id'])\n",
    "dfCatE = pd.DataFrame(lEntertainment, columns=['cat_name', 'cat_id'])\n",
    "dfCatL = pd.DataFrame(lLodging, columns=['cat_name', 'cat_id'])\n",
    "dfCatS = pd.DataFrame(lShopping, columns=['cat_name', 'cat_id'])\n",
    "dfCatV = pd.DataFrame(lServices, columns=['cat_name', 'cat_id'])\n",
    "dfCatT = pd.DataFrame(lTransportation, columns=['cat_name', 'cat_id'])\n",
    "dfCategories = pd.concat([dfCatR, dfCatE, dfCatL, dfCatS, dfCatV, dfCatT], ignore_index=True)\n",
    "\n",
    "dfClassList = pd.concat([dfClasses, dfCategories], axis=1, ignore_index=False)\n",
    "print(dfClassList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClassList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of venue category id's for use in foursquare.com query\n",
    "# no quotes, no square brackets, comma separated, no extra spaces\n",
    "\n",
    "strClassList = ','.join(dfClassList['cat_id'].values)\n",
    "print(strClassList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataframe of stations and their amenities\n",
    "# stationID: foursquare's unique ID for each charging station\n",
    "# amenityID: foursquare's unique ID for each amenity (venue) nearby the charging station\n",
    "# amenityName: name of amenity \n",
    "# amenityLat: latitude of amenity\n",
    "# amenityLong: longitude of amenity\n",
    "# amenityCity: city of amenity\n",
    "# amenityCatID: primary category ID of amenity\n",
    "# amenityCatName: primary category name of amenity\n",
    "\n",
    "# intialize dataframe to hold stations & venues list & setup variables\n",
    "dfAmenities = pd.DataFrame()\n",
    "dfSummary = pd.DataFrame(columns=['stationID', 'countAmenities'])\n",
    "dfSummary['stationID'] = lStations['venue.id']\n",
    "nStations = len(lStations['venue.id'])\n",
    "# note: also use strClassList, defined earlier\n",
    "nRadius = 400     # radius to other venues: 400 m is approx 1/4 mile\n",
    "                  # reference: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3377942/\n",
    "                  # reference: https://www.smartcitiesdive.com/ex/sustainablecitiescollective/pedestrians-and-park-planning-how-far-will-people-walk/24937/\n",
    "nMax = 50         # maximum number of venues to retreive\n",
    "\n",
    "print(\"# of stations: \" + str(nStations))\n",
    "\n",
    "# retrieve nearby venues to each station in lStations\n",
    "# also create a list of # of nearby amentities per station\n",
    "for iStation in range(nStations):\n",
    "    xLat = lStations.loc[iStation, 'venue.location.lat']\n",
    "    xLong = lStations.loc[iStation, 'venue.location.lng']\n",
    "    \n",
    "    print(\"Station # \" + str(iStation) + \": \")\n",
    "\n",
    "    url = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&v={}&ll={},{}&categoryId={}&radius={}&limit={}'.format(\n",
    "           CLIENT_ID, CLIENT_SECRET, VERSION, xLat, xLong, strClassList, nRadius, nMax)\n",
    "        \n",
    "    results = requests.get(url).json()\n",
    "    venues = results['response']['groups'][0]['items']\n",
    "    lAmenities = json_normalize(venues)                  # flatten JSON\n",
    "    filtered_columns = ['venue.id', 'venue.name', 'venue.location.lat', \n",
    "                        'venue.location.lng', 'venue.location.city', 'venue.categories']\n",
    "    lAmenities = lAmenities.loc[:, filtered_columns]\n",
    "    nAmenities = lAmenities.shape[0]\n",
    "    dfSummary.loc[iStation, 'countAmenities'] = nAmenities\n",
    "\n",
    "    # make list of venue category id's & venue category name's for each venue in lAmenities\n",
    "    print('# of nearby amenities: ' + str(nAmenities))\n",
    "    dfCategories = pd.DataFrame(columns=['catID', 'catName'])\n",
    "    for iAmenity in range(nAmenities):\n",
    "        dfCategories.loc[iAmenity] = [lAmenities['venue.categories'][iAmenity][0].get('id'), \n",
    "                             lAmenities['venue.categories'][iAmenity][0].get('name')]\n",
    "        # end for loop\n",
    "    dfAmenities = dfAmenities.append(list(zip(list(itertools.repeat(lStations['venue.id'][iStation],\n",
    "                                     nAmenities)), lAmenities['venue.id'],\n",
    "                                     lAmenities['venue.name'], lAmenities['venue.location.lat'],\n",
    "                                     lAmenities['venue.location.lng'], lAmenities['venue.location.city'],\n",
    "                                     dfCategories['catID'].values,\n",
    "                                     dfCategories['catName'].values)),\n",
    "                                    ignore_index=True)\n",
    "# end for loop\n",
    "\n",
    "dfAmenities.rename(columns={0:'stationID', 1: 'amenityID', 2: 'amenityName', 3: 'amenityLat',\n",
    "                           4: 'amenityLong', 5: 'amenityCity', 6: 'amenityCatID', 7: 'amenityCatName'}, inplace=True)\n",
    "print(dfAmenities.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(dfSummary['countAmenities']))\n",
    "print(np.mean(dfSummary['countAmenities']))\n",
    "dfSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "\n",
    "dfAmenities = pd.concat([dfAmenities, pd.get_dummies(dfAmenities['amenityCatName'], \n",
    "              prefix='cat', dummy_na=True, prefix_sep='_')], axis=1)\n",
    "print(dfAmenities.head(20))\n",
    "\n",
    "# make list of column names & # column names available for use later\n",
    "lCols = list(dfAmenities.columns)\n",
    "nCols = len(list(dfAmenities.columns))\n",
    "print('# columns in dfAmenities: ' + str(nCols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for classification of stations by venue categories\n",
    "\n",
    "# create dataframe which only contains stationID & one-hot encoded amenity categories\n",
    "# to be used in classification\n",
    "# note: due to the way the dataframe was constructed, it is already sorted by stationID\n",
    "\n",
    "dfSubset = dfAmenities.copy(deep=False)\n",
    "lCols_encoded = [0] + list(np.arange(8, nCols))\n",
    "dfTestClassify = dfSubset[dfSubset.columns[lCols_encoded]]\n",
    "\n",
    "# prepare for classification\n",
    "dfTestClassify_grouped = dfTestClassify.groupby('stationID').mean().reset_index()\n",
    "dfTestClassify_noID = dfTestClassify.drop('stationID', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means clustering\n",
    "\n",
    "kClusters = 5            # arbitrarily choose # of clusters\n",
    "kmStations = KMeans(n_clusters=kClusters, random_state=0).fit(dfTestClassify_noID)\n",
    "lGroups = kmStations.labels_\n",
    "dfGroups = pd.DataFrame(zip(dfTestClassify_grouped['stationID'], lGroups), columns=['stationID','Group'])\n",
    "print(dfGroups.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the group # assigned by k-means clustering analysis to the list of stations & amenity categories\n",
    "dfTestClassify_merged = dfTestClassify_grouped.join(dfGroups.set_index('stationID'), on='stationID')\n",
    "print(dfTestClassify_merged.head(20))\n",
    "\n",
    "# add lat/long information per stationID\n",
    "dfLocations = pd.DataFrame(zip(lStations['venue.id'],\n",
    "                               lStations['venue.name'],\n",
    "                               lStations['venue.location.lat'],\n",
    "                               lStations['venue.location.lng']), \n",
    "                           columns=['stationID', 'stationName', 'stationLat', 'stationLong'])\n",
    "dfClassify_locations = dfTestClassify_merged.join(dfLocations.set_index('stationID'), on='stationID')\n",
    "print(dfClassify_locations.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClassify_locations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count top amenity categories for each stationID\n",
    "\n",
    "# define function\n",
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:-2]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    return row_categories_sorted.index.values[0:num_top_venues]\n",
    "\n",
    "# initialize variables\n",
    "nTops = 5        # arbitrarily choose how many \"top venues\" (most common amenity categories) to show\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "lColumns = ['stationID']\n",
    "for ind in np.arange(nTops):\n",
    "    try:\n",
    "        lColumns.append('{}{} Most Common Category'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        lColumns.append('{}th Most Common Category'.format(ind+1))\n",
    "\n",
    "# count top # of items\n",
    "dfTops = pd.DataFrame(columns=lColumns)\n",
    "nCategories = dfTestClassify_grouped.shape[0]\n",
    "# note: nStations already defined above; nStations = # charging stations\n",
    "dfTops['stationID'] = dfTestClassify_grouped['stationID']\n",
    "for iRow in np.arange(nStations):             # for each row\n",
    "    dfTops.loc[iRow, 1:] = return_most_common_venues(dfTestClassify.iloc[iRow, :], nTops)\n",
    "\n",
    "# add group #'s to list of top categories\n",
    "dfTops = dfTops.join(dfGroups.set_index('stationID'), on='stationID')\n",
    "dfTops = dfTops.reindex(columns=['stationID','Group'] + list(dfTops.columns[1:-1]))\n",
    "\n",
    "# add # amenities per stationID\n",
    "dfTops = dfTops.join(dfSummary.set_index('stationID'), on='stationID')\n",
    "print(dfTops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTops.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map results of k-means clustering of charging stations on nearby amenities\n",
    "\n",
    "# set map starting location\n",
    "# note: use geopy to get lat/long of Los Angeles\n",
    "mapAddress = 'Los Angeles, CA'\n",
    "geolocator = Nominatim(user_agent=\"TO_explorer\")\n",
    "location = geolocator.geocode(mapAddress)\n",
    "mapLat = location.latitude\n",
    "mapLong = location.longitude\n",
    "\n",
    "# create cluster map\n",
    "map_clusters = folium.Map(location=[mapLat, mapLong], tiles='cartodbpositron', \n",
    "                          zoom_start=9)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kClusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kClusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster, countAmenities in zip(dfClassify_locations['stationLat'], \n",
    "                                  dfClassify_locations['stationLong'], \n",
    "                                  dfClassify_locations['stationName'], \n",
    "                                  dfClassify_locations['Group'],\n",
    "                                  dfTops['countAmenities']):\n",
    "    label = folium.Popup(str(poi) + ' - Group # ' + str(cluster) + ' - ' + \n",
    "                         str(countAmenities) + ' nearby amenities', parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=2 + countAmenities / 2,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Note:</i> On the map, above, the size of the circular marker represents the number of nearby amenities.  Larger circles indicate more amenities within 1/4 mile of the charging station.  Colors indicate classification groups, based on types of nearby amenities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
